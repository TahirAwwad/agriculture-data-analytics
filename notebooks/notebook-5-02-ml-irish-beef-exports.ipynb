{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06dfb6aa",
   "metadata": {},
   "source": [
    "## Beef & cattle export model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a36702",
   "metadata": {},
   "source": [
    "<!--\n",
    "import data_analytics.github as github\n",
    "print(github.create_jupyter_notebook_header(\"markcrowe-com\", \"agriculture-data-analytics\", \"notebooks/notebook-3-01-ml-beef-exports.ipynb\", \"master\"))\n",
    "-->\n",
    "<table style=\"margin: auto;\"><tr><td><a href=\"https://mybinder.org/v2/gh/markcrowe-com/agriculture-data-analytics/master?filepath=notebooks/notebook-3-01-ml-beef-exports.ipynb\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open In Binder\"/></a></td><td>online editors</td><td><a href=\"https://colab.research.google.com/github/markcrowe-com/agriculture-data-analytics/blob/master/notebooks/notebook-3-01-ml-beef-exports.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f4eda",
   "metadata": {},
   "source": [
    "The objective is to build a machine learning (ML) model of the [bovine-tuberculosis-eda-output.csv](./../artifacts/bovine-tuberculosis-eda-output.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55902df1",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d65b56",
   "metadata": {},
   "source": [
    "Import required third party Python libraries, import supporting functions and sets up data source file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760ece13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local\n",
    "#!pip install -r script/requirements.txt \n",
    "# Remote option\n",
    "#!pip install -r https://github.com/markcrowe-com/agriculture-data-analytics/blob/master/notebooks/script/requirements.txt --quiet --user\n",
    "# Command Line options include:--quiet, --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2782cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agriculture_data_analytics.project_manager import *\n",
    "from agriculture_data_analytics.dataframe_labels import *\n",
    "import pandas \n",
    "import numpy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#import data_analytics.exploratory_data_analysis as eda\n",
    "#import data_analytics.exploratory_data_analysis_reports as eda_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca8b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_manager: ProjectArtifactManager = ProjectArtifactManager()\n",
    "artifact_manager.is_remote = True\n",
    "github.display_jupyter_notebook_data_sources(\n",
    "    [artifact_manager.get_cattle_beef_exports_eda_filepath()])\n",
    "artifact_manager.is_remote = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39543089",
   "metadata": {},
   "source": [
    "### Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99092f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimensions \n",
      " (32, 57)\n",
      "\n",
      "data column info \n",
      " <bound method DataFrame.info of     Unnamed: 0  Year          UNIT  Agricultural Output at Basic Prices  \\\n",
      "0            0  1990  Euro Million                               5200.0   \n",
      "1            1  1991  Euro Million                               4994.4   \n",
      "2            2  1992  Euro Million                               5374.0   \n",
      "3            3  1993  Euro Million                               5625.9   \n",
      "4            4  1994  Euro Million                               5781.5   \n",
      "5            5  1995  Euro Million                               6035.5   \n",
      "6            6  1996  Euro Million                               6134.7   \n",
      "7            7  1997  Euro Million                               5753.1   \n",
      "8            8  1998  Euro Million                               5831.7   \n",
      "9            9  1999  Euro Million                               5651.4   \n",
      "10          10  2000  Euro Million                               5985.5   \n",
      "11          11  2001  Euro Million                               6066.8   \n",
      "12          12  2002  Euro Million                               5836.1   \n",
      "13          13  2003  Euro Million                               5979.1   \n",
      "14          14  2004  Euro Million                               6156.9   \n",
      "15          15  2005  Euro Million                               5710.7   \n",
      "16          16  2006  Euro Million                               5466.7   \n",
      "17          17  2007  Euro Million                               5975.4   \n",
      "18          18  2008  Euro Million                               6143.0   \n",
      "19          19  2009  Euro Million                               5014.0   \n",
      "20          20  2010  Euro Million                               5822.1   \n",
      "21          21  2011  Euro Million                               6576.2   \n",
      "22          22  2012  Euro Million                               6837.5   \n",
      "23          23  2013  Euro Million                               7671.6   \n",
      "24          24  2014  Euro Million                               7293.9   \n",
      "25          25  2015  Euro Million                               7404.2   \n",
      "26          26  2016  Euro Million                               7444.2   \n",
      "27          27  2017  Euro Million                               8476.4   \n",
      "28          28  2018  Euro Million                               8663.7   \n",
      "29          29  2019  Euro Million                               8516.4   \n",
      "30          30  2020  Euro Million                               8908.3   \n",
      "31          31  2021  Euro Million                               9972.9   \n",
      "\n",
      "    All Cereals  All Crops  All Livestock  All Livestock Products  \\\n",
      "0         216.7     1123.5         2201.9                  1360.0   \n",
      "1         218.6     1127.3         2114.0                  1301.9   \n",
      "2         235.4     1154.4         2262.5                  1410.7   \n",
      "3         165.7     1101.7         2449.6                  1476.7   \n",
      "4         127.3     1157.0         2319.3                  1487.6   \n",
      "5         159.4     1217.2         2349.1                  1580.8   \n",
      "6         200.9     1268.7         2318.2                  1573.9   \n",
      "7         160.0     1102.6         2205.5                  1450.9   \n",
      "8         143.1     1127.9         2152.5                  1465.9   \n",
      "9         164.1     1184.3         2067.9                  1438.1   \n",
      "10        185.1     1228.6         2170.6                  1484.3   \n",
      "11        169.8     1322.5         2175.1                  1604.2   \n",
      "12        141.9     1245.3         2014.8                  1451.0   \n",
      "13        171.7     1302.7         2065.4                  1470.6   \n",
      "14        181.4     1350.6         2212.8                  1459.3   \n",
      "15        125.7     1378.1         2273.8                  1389.5   \n",
      "16        159.7     1461.3         2386.8                  1380.2   \n",
      "17        241.8     1632.7         2378.7                  1716.1   \n",
      "18        197.0     1657.1         2541.7                  1681.5   \n",
      "19        107.0     1377.9         2222.8                  1153.9   \n",
      "20        192.9     1670.0         2259.6                  1583.9   \n",
      "21        290.1     1715.9         2644.8                  1891.1   \n",
      "22        334.9     1784.5         3065.0                  1692.3   \n",
      "23        289.6     2066.4         3147.6                  2132.3   \n",
      "24        280.5     1747.5         3070.1                  2151.3   \n",
      "25        262.7     1737.3         3452.5                  1949.4   \n",
      "26        230.8     1767.4         3440.2                  1857.8   \n",
      "27        237.2     1824.6         3592.4                  2668.7   \n",
      "28        288.4     2126.0         3431.4                  2639.2   \n",
      "29        327.2     1893.6         3372.4                  2689.7   \n",
      "30        289.5     1942.9         3591.8                  2832.0   \n",
      "31        421.9     2120.5         3892.0                  3460.0   \n",
      "\n",
      "    All Livestock Products - Milk  \\\n",
      "0                          1316.3   \n",
      "1                          1258.9   \n",
      "2                          1373.1   \n",
      "3                          1439.0   \n",
      "4                          1446.2   \n",
      "5                          1538.5   \n",
      "6                          1536.0   \n",
      "7                          1414.5   \n",
      "8                          1431.2   \n",
      "9                          1408.8   \n",
      "10                         1447.1   \n",
      "11                         1566.1   \n",
      "12                         1413.0   \n",
      "13                         1431.3   \n",
      "14                         1417.8   \n",
      "15                         1342.1   \n",
      "16                         1332.5   \n",
      "17                         1667.5   \n",
      "18                         1628.1   \n",
      "19                         1106.5   \n",
      "20                         1541.9   \n",
      "21                         1834.8   \n",
      "22                         1629.8   \n",
      "23                         2073.4   \n",
      "24                         2093.1   \n",
      "25                         1881.1   \n",
      "26                         1790.8   \n",
      "27                         2594.1   \n",
      "28                         2556.7   \n",
      "29                         2608.6   \n",
      "30                         2752.7   \n",
      "31                         3376.6   \n",
      "\n",
      "    All Livestock Products Other Products (excluding Milk)  ...  \\\n",
      "0                                                43.7       ...   \n",
      "1                                                43.0       ...   \n",
      "2                                                37.6       ...   \n",
      "3                                                37.7       ...   \n",
      "4                                                41.4       ...   \n",
      "5                                                42.3       ...   \n",
      "6                                                37.9       ...   \n",
      "7                                                36.3       ...   \n",
      "8                                                34.7       ...   \n",
      "9                                                29.3       ...   \n",
      "10                                               37.2       ...   \n",
      "11                                               38.1       ...   \n",
      "12                                               37.9       ...   \n",
      "13                                               39.3       ...   \n",
      "14                                               41.6       ...   \n",
      "15                                               47.3       ...   \n",
      "16                                               47.7       ...   \n",
      "17                                               48.6       ...   \n",
      "18                                               53.4       ...   \n",
      "19                                               47.4       ...   \n",
      "20                                               42.0       ...   \n",
      "21                                               56.3       ...   \n",
      "22                                               62.6       ...   \n",
      "23                                               58.9       ...   \n",
      "24                                               58.2       ...   \n",
      "25                                               68.3       ...   \n",
      "26                                               67.0       ...   \n",
      "27                                               74.6       ...   \n",
      "28                                               82.6       ...   \n",
      "29                                               81.1       ...   \n",
      "30                                               79.2       ...   \n",
      "31                                               83.4       ...   \n",
      "\n",
      "    Livestock - Horses  Livestock - Pig  Livestock - Poultry  \\\n",
      "0                 83.2            237.2                117.1   \n",
      "1                 70.2            242.1                125.5   \n",
      "2                 61.4            280.4                124.5   \n",
      "3                 84.5            257.9                116.0   \n",
      "4                 75.9            264.5                134.6   \n",
      "5                 70.1            295.5                133.8   \n",
      "6                 96.9            356.5                140.4   \n",
      "7                106.9            337.0                149.1   \n",
      "8                128.7            282.6                142.2   \n",
      "9                150.0            251.4                137.8   \n",
      "10               164.4            296.7                124.0   \n",
      "11               146.5            346.1                137.7   \n",
      "12               200.7            300.9                132.1   \n",
      "13               204.3            285.1                138.7   \n",
      "14               217.6            297.5                151.2   \n",
      "15               234.0            292.9                146.5   \n",
      "16               263.5            321.5                114.3   \n",
      "17               269.3            288.6                133.0   \n",
      "18               228.5            330.1                122.7   \n",
      "19               172.7            300.0                115.1   \n",
      "20               145.9            333.7                112.2   \n",
      "21               135.6            394.2                130.1   \n",
      "22               166.7            441.5                132.9   \n",
      "23               186.5            475.7                129.9   \n",
      "24               221.7            471.3                133.3   \n",
      "25               247.3            456.3                142.2   \n",
      "26               270.5            465.6                159.5   \n",
      "27               287.4            516.8                163.1   \n",
      "28               306.4            459.1                159.0   \n",
      "29               255.5            543.0                169.2   \n",
      "30               216.1            601.9                180.0   \n",
      "31               257.2            565.1                187.9   \n",
      "\n",
      "    Livestock - Sheep  Net Value Added at Basic Prices  Operating Surplus  \\\n",
      "0               188.8                           2306.3             1943.5   \n",
      "1               198.9                           2126.2             1774.0   \n",
      "2               192.8                           2484.9             2179.4   \n",
      "3               232.4                           2560.6             2247.9   \n",
      "4               230.2                           2513.7             2278.5   \n",
      "5               190.7                           2612.3             2375.3   \n",
      "6               241.8                           2518.5             2423.2   \n",
      "7               230.0                           2291.0             2233.1   \n",
      "8               214.0                           2270.1             2229.1   \n",
      "9               198.0                           1973.9             1930.5   \n",
      "10              203.5                           2188.4             2163.0   \n",
      "11              284.4                           1979.6             2177.1   \n",
      "12              202.2                           1786.8             2024.8   \n",
      "13              193.3                           1874.6             2060.7   \n",
      "14              200.4                           1989.0             2177.4   \n",
      "15              194.2                           1318.4             2589.9   \n",
      "16              193.1                            784.0             2185.6   \n",
      "17              184.5                           1045.8             2442.0   \n",
      "18              173.8                            673.6             2118.3   \n",
      "19              159.4                             43.8             1429.0   \n",
      "20              165.6                            654.9             1841.5   \n",
      "21              189.8                           1159.5             2515.8   \n",
      "22              204.4                           1066.7             2280.7   \n",
      "23              203.8                           1289.7             2355.9   \n",
      "24              231.6                           1411.1             2441.2   \n",
      "25              245.2                           1666.3             2587.2   \n",
      "26              255.7                           1545.6             2626.0   \n",
      "27              262.9                           2309.2             3422.1   \n",
      "28              258.8                           1708.0             2823.0   \n",
      "29              260.8                           1881.1             2924.8   \n",
      "30              303.3                           2233.8             3262.8   \n",
      "31              361.9                           2906.0             3851.7   \n",
      "\n",
      "    Other Subsidies Less Taxes on Production  \\\n",
      "0                                       14.8   \n",
      "1                                       10.3   \n",
      "2                                       31.4   \n",
      "3                                       26.3   \n",
      "4                                      110.0   \n",
      "5                                      125.8   \n",
      "6                                      247.9   \n",
      "7                                      290.4   \n",
      "8                                      318.9   \n",
      "9                                      331.6   \n",
      "10                                     356.5   \n",
      "11                                     569.0   \n",
      "12                                     616.1   \n",
      "13                                     577.2   \n",
      "14                                     592.4   \n",
      "15                                    1680.5   \n",
      "16                                    1826.9   \n",
      "17                                    1844.9   \n",
      "18                                    1880.9   \n",
      "19                                    1812.9   \n",
      "20                                    1651.3   \n",
      "21                                    1831.7   \n",
      "22                                    1682.0   \n",
      "23                                    1557.6   \n",
      "24                                    1525.8   \n",
      "25                                    1409.9   \n",
      "26                                    1593.4   \n",
      "27                                    1638.5   \n",
      "28                                    1682.8   \n",
      "29                                    1630.0   \n",
      "30                                    1646.5   \n",
      "31                                    1600.2   \n",
      "\n",
      "    Subsidies less Taxes on Products  Subsidies on Products  Taxes on Products  \n",
      "0                              333.9                  408.9               75.0  \n",
      "1                              279.1                  357.3               78.2  \n",
      "2                              366.6                  446.0               79.5  \n",
      "3                              398.4                  466.4               68.0  \n",
      "4                              612.3                  666.0               53.7  \n",
      "5                              676.0                  735.6               59.6  \n",
      "6                              753.0                  806.0               53.0  \n",
      "7                              769.0                  808.7               39.8  \n",
      "8                              860.2                  899.6               39.4  \n",
      "9                              715.8                  743.7               27.9  \n",
      "10                             843.8                  876.7               32.8  \n",
      "11                             685.8                  710.8               25.0  \n",
      "12                             876.7                  904.1               27.4  \n",
      "13                             892.5                  928.4               35.8  \n",
      "14                             873.0                  912.1               39.1  \n",
      "15                             399.2                  453.4               54.2  \n",
      "16                             -33.1                    3.8               36.8  \n",
      "17                             -40.4                    0.7               41.1  \n",
      "18                             -18.3                   32.4               50.7  \n",
      "19                              -9.3                   30.0               39.3  \n",
      "20                             -10.5                   31.8               42.3  \n",
      "21                             -11.0                   31.0               42.0  \n",
      "22                             -28.1                   28.5               56.7  \n",
      "23                             -40.5                    9.4               49.8  \n",
      "24                             -33.7                   28.8               62.5  \n",
      "25                             -82.9                   43.2              126.2  \n",
      "26                               7.1                   55.9               48.8  \n",
      "27                              11.0                   60.5               49.5  \n",
      "28                              13.9                   65.1               51.2  \n",
      "29                              99.5                  150.6               51.1  \n",
      "30                              94.6                  147.2               52.6  \n",
      "31                              53.4                    NaN                NaN  \n",
      "\n",
      "[32 rows x 57 columns]>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./../artifacts/cattle-beef-exports-eda-output.csv\")\n",
    "print(\"data dimensions \\n\",df.shape)\n",
    "print()\n",
    "print(\"data column info \\n\",df.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d0d037",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>Agricultural Output at Basic Prices</th>\n",
       "      <th>All Cereals</th>\n",
       "      <th>All Crops</th>\n",
       "      <th>All Livestock</th>\n",
       "      <th>All Livestock Products</th>\n",
       "      <th>All Livestock Products - Milk</th>\n",
       "      <th>All Livestock Products Other Products (excluding Milk)</th>\n",
       "      <th>...</th>\n",
       "      <th>Livestock - Horses</th>\n",
       "      <th>Livestock - Pig</th>\n",
       "      <th>Livestock - Poultry</th>\n",
       "      <th>Livestock - Sheep</th>\n",
       "      <th>Net Value Added at Basic Prices</th>\n",
       "      <th>Operating Surplus</th>\n",
       "      <th>Other Subsidies Less Taxes on Production</th>\n",
       "      <th>Subsidies less Taxes on Products</th>\n",
       "      <th>Subsidies on Products</th>\n",
       "      <th>Taxes on Products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>Euro Million</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>216.7</td>\n",
       "      <td>1123.5</td>\n",
       "      <td>2201.9</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>1316.3</td>\n",
       "      <td>43.7</td>\n",
       "      <td>...</td>\n",
       "      <td>83.2</td>\n",
       "      <td>237.2</td>\n",
       "      <td>117.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>2306.3</td>\n",
       "      <td>1943.5</td>\n",
       "      <td>14.8</td>\n",
       "      <td>333.9</td>\n",
       "      <td>408.9</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>Euro Million</td>\n",
       "      <td>4994.4</td>\n",
       "      <td>218.6</td>\n",
       "      <td>1127.3</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>1301.9</td>\n",
       "      <td>1258.9</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.2</td>\n",
       "      <td>242.1</td>\n",
       "      <td>125.5</td>\n",
       "      <td>198.9</td>\n",
       "      <td>2126.2</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>279.1</td>\n",
       "      <td>357.3</td>\n",
       "      <td>78.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1992</td>\n",
       "      <td>Euro Million</td>\n",
       "      <td>5374.0</td>\n",
       "      <td>235.4</td>\n",
       "      <td>1154.4</td>\n",
       "      <td>2262.5</td>\n",
       "      <td>1410.7</td>\n",
       "      <td>1373.1</td>\n",
       "      <td>37.6</td>\n",
       "      <td>...</td>\n",
       "      <td>61.4</td>\n",
       "      <td>280.4</td>\n",
       "      <td>124.5</td>\n",
       "      <td>192.8</td>\n",
       "      <td>2484.9</td>\n",
       "      <td>2179.4</td>\n",
       "      <td>31.4</td>\n",
       "      <td>366.6</td>\n",
       "      <td>446.0</td>\n",
       "      <td>79.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1993</td>\n",
       "      <td>Euro Million</td>\n",
       "      <td>5625.9</td>\n",
       "      <td>165.7</td>\n",
       "      <td>1101.7</td>\n",
       "      <td>2449.6</td>\n",
       "      <td>1476.7</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>...</td>\n",
       "      <td>84.5</td>\n",
       "      <td>257.9</td>\n",
       "      <td>116.0</td>\n",
       "      <td>232.4</td>\n",
       "      <td>2560.6</td>\n",
       "      <td>2247.9</td>\n",
       "      <td>26.3</td>\n",
       "      <td>398.4</td>\n",
       "      <td>466.4</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1994</td>\n",
       "      <td>Euro Million</td>\n",
       "      <td>5781.5</td>\n",
       "      <td>127.3</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>2319.3</td>\n",
       "      <td>1487.6</td>\n",
       "      <td>1446.2</td>\n",
       "      <td>41.4</td>\n",
       "      <td>...</td>\n",
       "      <td>75.9</td>\n",
       "      <td>264.5</td>\n",
       "      <td>134.6</td>\n",
       "      <td>230.2</td>\n",
       "      <td>2513.7</td>\n",
       "      <td>2278.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>612.3</td>\n",
       "      <td>666.0</td>\n",
       "      <td>53.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Year          UNIT  Agricultural Output at Basic Prices  \\\n",
       "0           0  1990  Euro Million                               5200.0   \n",
       "1           1  1991  Euro Million                               4994.4   \n",
       "2           2  1992  Euro Million                               5374.0   \n",
       "3           3  1993  Euro Million                               5625.9   \n",
       "4           4  1994  Euro Million                               5781.5   \n",
       "\n",
       "   All Cereals  All Crops  All Livestock  All Livestock Products  \\\n",
       "0        216.7     1123.5         2201.9                  1360.0   \n",
       "1        218.6     1127.3         2114.0                  1301.9   \n",
       "2        235.4     1154.4         2262.5                  1410.7   \n",
       "3        165.7     1101.7         2449.6                  1476.7   \n",
       "4        127.3     1157.0         2319.3                  1487.6   \n",
       "\n",
       "   All Livestock Products - Milk  \\\n",
       "0                         1316.3   \n",
       "1                         1258.9   \n",
       "2                         1373.1   \n",
       "3                         1439.0   \n",
       "4                         1446.2   \n",
       "\n",
       "   All Livestock Products Other Products (excluding Milk)  ...  \\\n",
       "0                                               43.7       ...   \n",
       "1                                               43.0       ...   \n",
       "2                                               37.6       ...   \n",
       "3                                               37.7       ...   \n",
       "4                                               41.4       ...   \n",
       "\n",
       "   Livestock - Horses  Livestock - Pig  Livestock - Poultry  \\\n",
       "0                83.2            237.2                117.1   \n",
       "1                70.2            242.1                125.5   \n",
       "2                61.4            280.4                124.5   \n",
       "3                84.5            257.9                116.0   \n",
       "4                75.9            264.5                134.6   \n",
       "\n",
       "   Livestock - Sheep  Net Value Added at Basic Prices  Operating Surplus  \\\n",
       "0              188.8                           2306.3             1943.5   \n",
       "1              198.9                           2126.2             1774.0   \n",
       "2              192.8                           2484.9             2179.4   \n",
       "3              232.4                           2560.6             2247.9   \n",
       "4              230.2                           2513.7             2278.5   \n",
       "\n",
       "   Other Subsidies Less Taxes on Production  Subsidies less Taxes on Products  \\\n",
       "0                                      14.8                             333.9   \n",
       "1                                      10.3                             279.1   \n",
       "2                                      31.4                             366.6   \n",
       "3                                      26.3                             398.4   \n",
       "4                                     110.0                             612.3   \n",
       "\n",
       "   Subsidies on Products  Taxes on Products  \n",
       "0                  408.9               75.0  \n",
       "1                  357.3               78.2  \n",
       "2                  446.0               79.5  \n",
       "3                  466.4               68.0  \n",
       "4                  666.0               53.7  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#eda_reports.print_dataframe_analysis_report(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dce267",
   "metadata": {},
   "source": [
    "## Production of Milk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a096f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milk production dataset dimenssions \n",
      " (32, 25)\n"
     ]
    }
   ],
   "source": [
    "## Extract milk production dataset\n",
    "# drop redundunt columns\n",
    "df = df.drop('Unnamed: 0',axis = 1)\n",
    "\n",
    "# extract milk dataset\n",
    "df_milk = df[['Year',\n",
    "#              'UNIT',\n",
    "              'All Livestock Products - Milk',\n",
    "              'Taxes on Products',\n",
    "              'Subsidies on Products',\n",
    "              'Compensation of Employees',\n",
    "              'Contract Work',\n",
    "              'Entrepreneurial Income',\n",
    "              'Factor Income',\n",
    "              'Fixed Capital Consumption - Farm Buildings',\n",
    "              'Fixed Capital Consumption - Machinery, Equipment, etc',\n",
    "              'Interest less FISIM',\n",
    "              'Operating Surplus',\n",
    "              'Livestock - Cattle',\n",
    "              'Livestock - Sheep',\n",
    "              'Land Rental',\n",
    "              'Intermediate Consumption - Contract Work',\n",
    "              'Intermediate Consumption - Crop Protection Products',\n",
    "              'Intermediate Consumption - Energy and Lubricants',\n",
    "              'Intermediate Consumption - Feeding Stuffs',\n",
    "              'Intermediate Consumption - Fertilisers',\n",
    "              'Intermediate Consumption - Financial Intermediation Services Indirect',\n",
    "              'Intermediate Consumption - Forage Plants',\n",
    "              'Intermediate Consumption - Maintenance and Repairs',\n",
    "              'Intermediate Consumption - Seeds',\n",
    "              #'Intermediate Consumption - Services',\n",
    "              'Intermediate Consumption - Veterinary Expenses',\n",
    "              'Intermediate Consumption - Other Goods (Detergents, Small Tools, etc)',\n",
    "              #'Intermediate Consumption - Other Goods and Services'\n",
    "              \n",
    "             ]]\n",
    "# Assign year as index\n",
    "df_milk.set_index('Year',drop=True,inplace=True)\n",
    "\n",
    "print(\"Milk production dataset dimenssions \\n\", df_milk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a418fbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#eda_reports.print_dataframe_analysis_report(df_milk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b59fc",
   "metadata": {},
   "source": [
    "### Define 20% Training set 80% Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a3fb066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape  (32, 23)\n",
      "target shape  (32, 1)\n",
      "\n",
      "x_train shape  (25, 23)\n",
      "y_train shape  (25, 1)\n",
      "\n",
      "x_test shape  (7, 23)\n",
      "y_test shape  (7, 1)\n"
     ]
    }
   ],
   "source": [
    "# define target & feature variables\n",
    "\n",
    "X = df_milk.iloc[:,2:].values\n",
    "Y = df_milk.iloc[:,1].values.reshape(-1,1)\n",
    "print('features shape ',np.shape(X))\n",
    "print('target shape ',np.shape(Y))\n",
    "\n",
    "# impute mean value for NA\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X = imp_mean.fit_transform(X)\n",
    "Y = imp_mean.fit_transform(Y)\n",
    "\n",
    "\n",
    "# split train test split 20\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=2021)\n",
    "print()\n",
    "print('x_train shape ', X_train.shape)\n",
    "print('y_train shape ', Y_train.shape)\n",
    "print()\n",
    "print('x_test shape ', X_test.shape)\n",
    "print('y_test shape ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d8a1eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n",
      "MinMaxScaler()\n",
      "MinMaxScaler()\n",
      "MinMaxScaler()\n"
     ]
    }
   ],
   "source": [
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "print(scaler_x.fit(X_train))\n",
    "xtrain_scale=scaler_x.transform(X_train)\n",
    "\n",
    "print(scaler_y.fit(Y_train))\n",
    "ytrain_scale=scaler_y.transform(Y_train)\n",
    "\n",
    "print(scaler_x.fit(X_test))\n",
    "xtest_scale=scaler_x.transform(X_test)\n",
    "\n",
    "print(scaler_x.fit(Y_test))\n",
    "ytest_scale=scaler_y.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d24b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NAN values with the average  mean scaled\n",
    "#np.isnan(np.sum(xtrain_scale))\n",
    "#xtrain_scale[np.isnan(xtrain_scale)==True]= np.nanmean(xtrain_scale)\n",
    "#np.isnan(np.sum(ytrain_scale))\n",
    "#ytrain_scale[np.isnan(ytrain_scale)==True]= np.nanmean(ytrain_scale)\n",
    "#np.isnan(np.sum(xtest_scale))\n",
    "#xtest_scale[np.isnan(xtest_scale)==True]= np.nanmean(xtest_scale)\n",
    "#np.isnan(np.sum(ytest_scale))\n",
    "#ytest_scale[np.isnan(ytest_scale)==True]= np.nanmean(ytest_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f58f53",
   "metadata": {},
   "source": [
    "### Model 1 RandomForest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd779277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbe9bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_milk = RandomForestRegressor(random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4bc99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf_milk = {'n_estimators':[100,200,500],\n",
    "                  'criterion':['squared_error', 'absolute_error', 'poisson'],\n",
    "                  'max_features':[\"auto\"]\n",
    "                  \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "95bb5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_rf_milk = GridSearchCV(estimator= rf_model_milk,\n",
    "                     param_grid= params_rf_milk\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0cf7755c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'squared_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 350, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'absolute_error'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan -2.79485626 -2.41112613 -2.17976399 -2.15178205]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(random_state=2021),\n",
       "             param_grid={'criterion': ['squared_error', 'absolute_error',\n",
       "                                       'poisson'],\n",
       "                         'max_features': ['auto'],\n",
       "                         'n_estimators': [100, 200, 500, 1000]})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_rf_milk.fit(xtrain_scale,ytrain_scale.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f87b3065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(criterion='poisson', n_estimators=1000, random_state=2021)\n",
      "Best model score -2.151782053681818\n"
     ]
    }
   ],
   "source": [
    "# print best model\n",
    "print(GS_rf_milk.best_estimator_)\n",
    "print('Best model score', GS_rf_milk.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aab677",
   "metadata": {},
   "source": [
    "### Model 2 XGBOOST Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48d259a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/admin/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (1.5.1)\r\n",
      "Requirement already satisfied: scipy in /Users/admin/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from xgboost) (1.7.3)\r\n",
      "Requirement already satisfied: numpy in /Users/admin/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from xgboost) (1.22.0)\r\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "119a7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb_model_milk = XGBRegressor(random_state=2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "098523c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a search space of parameters to loop over\n",
    "\n",
    "params_xgb_milk = {'n_estimators':[20,40,80,160,340,500],\n",
    "             'max_depth':[3,6,9],\n",
    "             'gamma':[0.01,0.1],\n",
    "             'learning_rate':[0.001,0.01,0.1,1]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa5e885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_xgb_milk = GridSearchCV(estimator=xgb_model_milk,\n",
    "                     param_grid=params_xgb_milk,\n",
    "                     #n_jobs=-1,\n",
    "                     scoring=['r2','neg_root_mean_squared_error'],\n",
    "                     refit= 'r2',\n",
    "                     cv=5,\n",
    "                     verbose=4\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd170cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.280) r2: (test=-1.607) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.305) r2: (test=-23.320) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.186) r2: (test=-2.664) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.314) r2: (test=-8.101) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.364) r2: (test=-0.126) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.276) r2: (test=-1.527) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.300) r2: (test=-22.515) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.184) r2: (test=-2.585) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.312) r2: (test=-7.997) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.362) r2: (test=-0.115) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.267) r2: (test=-1.374) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.290) r2: (test=-20.992) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.180) r2: (test=-2.450) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.309) r2: (test=-7.812) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.096) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.251) r2: (test=-1.100) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.271) r2: (test=-18.194) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.175) r2: (test=-2.257) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.304) r2: (test=-7.522) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.354) r2: (test=-0.067) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.220) r2: (test=-0.614) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.230) r2: (test=-12.773) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.171) r2: (test=-2.127) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.298) r2: (test=-7.200) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.022) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.198) r2: (test=-0.299) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.199) r2: (test=-9.278) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.175) r2: (test=-2.254) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.299) r2: (test=-7.225) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.342) r2: (test=0.003) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.280) r2: (test=-1.607) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.305) r2: (test=-23.320) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.186) r2: (test=-2.664) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.314) r2: (test=-8.101) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.364) r2: (test=-0.126) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.276) r2: (test=-1.527) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.300) r2: (test=-22.515) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.184) r2: (test=-2.585) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.312) r2: (test=-7.997) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.362) r2: (test=-0.115) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.267) r2: (test=-1.374) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.290) r2: (test=-20.992) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.180) r2: (test=-2.450) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.309) r2: (test=-7.812) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.096) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.251) r2: (test=-1.100) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.271) r2: (test=-18.194) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.175) r2: (test=-2.257) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.304) r2: (test=-7.522) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.354) r2: (test=-0.067) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.220) r2: (test=-0.614) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.230) r2: (test=-12.773) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.171) r2: (test=-2.127) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.298) r2: (test=-7.200) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.022) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.198) r2: (test=-0.299) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.199) r2: (test=-9.278) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.176) r2: (test=-2.295) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.299) r2: (test=-7.228) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.342) r2: (test=0.003) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.280) r2: (test=-1.607) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.305) r2: (test=-23.320) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.186) r2: (test=-2.664) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.314) r2: (test=-8.101) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.364) r2: (test=-0.126) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.276) r2: (test=-1.527) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.300) r2: (test=-22.515) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.184) r2: (test=-2.585) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.312) r2: (test=-7.997) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.362) r2: (test=-0.115) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.267) r2: (test=-1.374) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.290) r2: (test=-20.992) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.180) r2: (test=-2.450) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.309) r2: (test=-7.812) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.096) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.251) r2: (test=-1.100) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.271) r2: (test=-18.194) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.175) r2: (test=-2.257) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.304) r2: (test=-7.522) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.354) r2: (test=-0.067) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.220) r2: (test=-0.614) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.230) r2: (test=-12.773) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.171) r2: (test=-2.127) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.298) r2: (test=-7.200) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.022) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.198) r2: (test=-0.299) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.199) r2: (test=-9.278) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.176) r2: (test=-2.295) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.299) r2: (test=-7.228) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.342) r2: (test=0.003) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.244) r2: (test=-0.975) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.262) r2: (test=-16.836) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.173) r2: (test=-2.193) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.302) r2: (test=-7.407) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.352) r2: (test=-0.055) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.211) r2: (test=-0.481) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.217) r2: (test=-11.309) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.172) r2: (test=-2.149) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.298) r2: (test=-7.178) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.345) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.162) r2: (test=0.123) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.152) r2: (test=-4.998) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.191) r2: (test=-2.897) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.308) r2: (test=-7.771) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.337) r2: (test=0.035) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.111) r2: (test=0.589) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.097) r2: (test=-1.437) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.553) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.352) r2: (test=-10.416) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.340) r2: (test=0.019) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.096) r2: (test=0.695) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.087) r2: (test=-0.963) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.303) r2: (test=-8.768) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.408) r2: (test=-14.349) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.344) r2: (test=-0.008) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.095) r2: (test=0.700) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.086) r2: (test=-0.948) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.302) r2: (test=-8.724) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.404) r2: (test=-14.083) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.346) r2: (test=-0.019) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.244) r2: (test=-0.975) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.262) r2: (test=-16.836) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.173) r2: (test=-2.193) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.302) r2: (test=-7.407) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.352) r2: (test=-0.055) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.211) r2: (test=-0.481) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.217) r2: (test=-11.309) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.172) r2: (test=-2.149) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.298) r2: (test=-7.176) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.345) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.161) r2: (test=0.135) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.152) r2: (test=-4.998) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.193) r2: (test=-2.967) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.308) r2: (test=-7.770) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.337) r2: (test=0.035) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.110) r2: (test=0.600) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.096) r2: (test=-1.392) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.245) r2: (test=-5.380) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.352) r2: (test=-10.410) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.340) r2: (test=0.019) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.094) r2: (test=0.708) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.086) r2: (test=-0.910) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.299) r2: (test=-8.482) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.407) r2: (test=-14.316) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.344) r2: (test=-0.008) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.093) r2: (test=0.713) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.085) r2: (test=-0.899) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.298) r2: (test=-8.426) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.404) r2: (test=-14.053) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.346) r2: (test=-0.019) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.244) r2: (test=-0.975) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.262) r2: (test=-16.836) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.173) r2: (test=-2.193) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.302) r2: (test=-7.407) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.352) r2: (test=-0.055) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.211) r2: (test=-0.481) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.217) r2: (test=-11.309) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.172) r2: (test=-2.149) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.298) r2: (test=-7.176) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.345) r2: (test=-0.010) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.161) r2: (test=0.135) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.152) r2: (test=-4.998) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.193) r2: (test=-2.967) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.308) r2: (test=-7.770) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.337) r2: (test=0.035) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.110) r2: (test=0.600) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.096) r2: (test=-1.392) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.245) r2: (test=-5.380) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.352) r2: (test=-10.410) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.340) r2: (test=0.019) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.094) r2: (test=0.708) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.086) r2: (test=-0.910) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.299) r2: (test=-8.482) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.407) r2: (test=-14.316) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.344) r2: (test=-0.008) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.093) r2: (test=0.713) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.085) r2: (test=-0.899) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.298) r2: (test=-8.426) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.404) r2: (test=-14.053) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.346) r2: (test=-0.019) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.106) r2: (test=0.628) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.084) r2: (test=-0.848) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.273) r2: (test=-6.902) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.375) r2: (test=-11.955) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.340) r2: (test=0.018) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.101) r2: (test=0.662) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.088) r2: (test=-1.004) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.303) r2: (test=-8.758) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.408) r2: (test=-14.326) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.346) r2: (test=-0.017) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.100) r2: (test=0.667) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.088) r2: (test=-1.003) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.303) r2: (test=-8.733) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.406) r2: (test=-14.168) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.100) r2: (test=0.667) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.088) r2: (test=-1.003) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.303) r2: (test=-8.732) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.165) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.100) r2: (test=0.667) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.088) r2: (test=-1.003) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.303) r2: (test=-8.732) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.165) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.100) r2: (test=0.667) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.088) r2: (test=-1.003) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.303) r2: (test=-8.732) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.165) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.102) r2: (test=0.654) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.083) r2: (test=-0.805) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.268) r2: (test=-6.647) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.375) r2: (test=-11.959) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.340) r2: (test=0.018) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.093) r2: (test=0.710) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.083) r2: (test=-0.795) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.298) r2: (test=-8.438) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.406) r2: (test=-14.211) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.346) r2: (test=-0.017) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.093) r2: (test=0.713) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.083) r2: (test=-0.795) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.297) r2: (test=-8.404) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.404) r2: (test=-14.080) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.093) r2: (test=0.713) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.083) r2: (test=-0.795) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.297) r2: (test=-8.404) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.404) r2: (test=-14.076) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.093) r2: (test=0.713) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.083) r2: (test=-0.795) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.297) r2: (test=-8.404) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.404) r2: (test=-14.076) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.093) r2: (test=0.713) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.083) r2: (test=-0.795) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.297) r2: (test=-8.404) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.404) r2: (test=-14.076) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.102) r2: (test=0.654) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.083) r2: (test=-0.805) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.268) r2: (test=-6.647) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.375) r2: (test=-11.959) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.340) r2: (test=0.018) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.093) r2: (test=0.710) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.083) r2: (test=-0.795) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.298) r2: (test=-8.438) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.406) r2: (test=-14.211) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.346) r2: (test=-0.017) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.093) r2: (test=0.713) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.083) r2: (test=-0.795) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.297) r2: (test=-8.404) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.404) r2: (test=-14.080) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.093) r2: (test=0.713) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.083) r2: (test=-0.795) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.297) r2: (test=-8.404) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.404) r2: (test=-14.076) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.093) r2: (test=0.713) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.083) r2: (test=-0.795) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.297) r2: (test=-8.404) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.404) r2: (test=-14.076) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.093) r2: (test=0.713) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.083) r2: (test=-0.795) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.297) r2: (test=-8.404) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.404) r2: (test=-14.076) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.108) r2: (test=0.612) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.104) r2: (test=-1.811) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.330) r2: (test=-10.561) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.405) r2: (test=-14.120) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.339) r2: (test=0.024) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.280) r2: (test=-1.607) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.305) r2: (test=-23.283) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.186) r2: (test=-2.664) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.314) r2: (test=-8.103) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.364) r2: (test=-0.126) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.276) r2: (test=-1.527) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.300) r2: (test=-22.435) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.184) r2: (test=-2.585) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.312) r2: (test=-8.003) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.362) r2: (test=-0.115) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.267) r2: (test=-1.376) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.289) r2: (test=-20.832) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.180) r2: (test=-2.450) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.309) r2: (test=-7.824) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.096) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.252) r2: (test=-1.107) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.270) r2: (test=-17.949) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.175) r2: (test=-2.257) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.304) r2: (test=-7.548) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.354) r2: (test=-0.063) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.226) r2: (test=-0.692) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.230) r2: (test=-12.769) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.172) r2: (test=-2.131) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.299) r2: (test=-7.250) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.345) r2: (test=-0.014) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.208) r2: (test=-0.432) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.203) r2: (test=-9.695) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.177) r2: (test=-2.342) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.300) r2: (test=-7.322) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.342) r2: (test=0.007) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.280) r2: (test=-1.607) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.305) r2: (test=-23.283) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.186) r2: (test=-2.664) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.314) r2: (test=-8.103) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.364) r2: (test=-0.126) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.276) r2: (test=-1.527) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.300) r2: (test=-22.435) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.184) r2: (test=-2.585) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.312) r2: (test=-8.003) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.362) r2: (test=-0.115) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.267) r2: (test=-1.376) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.289) r2: (test=-20.832) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.180) r2: (test=-2.450) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.309) r2: (test=-7.824) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.096) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.252) r2: (test=-1.107) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.270) r2: (test=-17.949) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.175) r2: (test=-2.257) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.304) r2: (test=-7.548) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.354) r2: (test=-0.063) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.226) r2: (test=-0.692) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.230) r2: (test=-12.769) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.172) r2: (test=-2.131) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.299) r2: (test=-7.250) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.345) r2: (test=-0.014) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.208) r2: (test=-0.432) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.203) r2: (test=-9.695) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.177) r2: (test=-2.342) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.300) r2: (test=-7.322) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.342) r2: (test=0.007) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.280) r2: (test=-1.607) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.305) r2: (test=-23.283) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.186) r2: (test=-2.664) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.314) r2: (test=-8.103) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.364) r2: (test=-0.126) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.276) r2: (test=-1.527) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.300) r2: (test=-22.435) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.184) r2: (test=-2.585) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.312) r2: (test=-8.003) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.362) r2: (test=-0.115) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.267) r2: (test=-1.376) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.289) r2: (test=-20.832) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.180) r2: (test=-2.450) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.309) r2: (test=-7.824) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.096) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.252) r2: (test=-1.107) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.270) r2: (test=-17.949) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.175) r2: (test=-2.257) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.304) r2: (test=-7.548) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.354) r2: (test=-0.063) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.226) r2: (test=-0.692) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.230) r2: (test=-12.769) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.172) r2: (test=-2.131) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.299) r2: (test=-7.250) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.345) r2: (test=-0.014) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.208) r2: (test=-0.432) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.203) r2: (test=-9.695) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.177) r2: (test=-2.342) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.300) r2: (test=-7.322) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.342) r2: (test=0.007) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.245) r2: (test=-0.998) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.260) r2: (test=-16.620) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.173) r2: (test=-2.193) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.303) r2: (test=-7.441) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.351) r2: (test=-0.049) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.218) r2: (test=-0.582) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.218) r2: (test=-11.360) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.173) r2: (test=-2.182) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.299) r2: (test=-7.232) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.344) r2: (test=-0.004) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.185) r2: (test=-0.135) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.169) r2: (test=-6.459) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.197) r2: (test=-3.120) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.313) r2: (test=-8.048) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.340) r2: (test=0.019) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.157) r2: (test=0.181) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.122) r2: (test=-2.911) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.207) r2: (test=-3.550) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.299) r2: (test=-7.233) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.345) r2: (test=-0.013) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.149) r2: (test=0.263) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.091) r2: (test=-1.144) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.205) r2: (test=-3.468) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.272) r2: (test=-5.806) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.354) r2: (test=-0.068) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.148) r2: (test=0.270) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.086) r2: (test=-0.910) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.205) r2: (test=-3.484) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.267) r2: (test=-5.581) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.081) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.245) r2: (test=-0.998) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.260) r2: (test=-16.620) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.173) r2: (test=-2.193) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.303) r2: (test=-7.441) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.351) r2: (test=-0.049) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.218) r2: (test=-0.582) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.218) r2: (test=-11.360) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.173) r2: (test=-2.182) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.299) r2: (test=-7.232) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.344) r2: (test=-0.004) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.185) r2: (test=-0.135) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.169) r2: (test=-6.459) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.197) r2: (test=-3.120) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.313) r2: (test=-8.048) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.340) r2: (test=0.019) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.157) r2: (test=0.181) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.122) r2: (test=-2.911) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.207) r2: (test=-3.550) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.299) r2: (test=-7.233) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.345) r2: (test=-0.013) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.149) r2: (test=0.263) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.091) r2: (test=-1.144) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.205) r2: (test=-3.468) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.272) r2: (test=-5.806) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.354) r2: (test=-0.068) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.148) r2: (test=0.270) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.086) r2: (test=-0.910) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.205) r2: (test=-3.484) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.267) r2: (test=-5.581) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.081) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.245) r2: (test=-0.998) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.260) r2: (test=-16.620) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.173) r2: (test=-2.193) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.303) r2: (test=-7.441) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.351) r2: (test=-0.049) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.218) r2: (test=-0.582) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.218) r2: (test=-11.360) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.173) r2: (test=-2.182) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.299) r2: (test=-7.232) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.344) r2: (test=-0.004) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.185) r2: (test=-0.135) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.169) r2: (test=-6.459) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.197) r2: (test=-3.120) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.313) r2: (test=-8.048) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.340) r2: (test=0.019) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.157) r2: (test=0.181) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.122) r2: (test=-2.911) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.207) r2: (test=-3.550) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.299) r2: (test=-7.233) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.345) r2: (test=-0.013) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.149) r2: (test=0.263) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.091) r2: (test=-1.144) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.205) r2: (test=-3.468) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.272) r2: (test=-5.806) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.354) r2: (test=-0.068) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.148) r2: (test=0.270) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.086) r2: (test=-0.910) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.205) r2: (test=-3.484) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.267) r2: (test=-5.581) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.081) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.152) r2: (test=0.230) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.106) r2: (test=-1.955) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.621) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.288) r2: (test=-6.672) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.295) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.085) r2: (test=-0.873) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.604) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.271) r2: (test=-5.759) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.356) r2: (test=-0.075) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.294) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.082) r2: (test=-0.752) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.615) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.268) r2: (test=-5.622) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.084) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.294) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.082) r2: (test=-0.749) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.615) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.268) r2: (test=-5.620) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.084) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.294) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.082) r2: (test=-0.749) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.615) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.268) r2: (test=-5.620) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.084) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.294) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.082) r2: (test=-0.749) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.615) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.268) r2: (test=-5.620) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.084) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.152) r2: (test=0.230) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.106) r2: (test=-1.955) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.621) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.288) r2: (test=-6.672) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.295) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.085) r2: (test=-0.873) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.604) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.271) r2: (test=-5.759) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.356) r2: (test=-0.075) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.294) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.082) r2: (test=-0.752) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.615) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.268) r2: (test=-5.622) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.084) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.294) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.082) r2: (test=-0.749) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.615) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.268) r2: (test=-5.620) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.084) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.294) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.082) r2: (test=-0.749) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.615) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.268) r2: (test=-5.620) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.084) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.294) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.082) r2: (test=-0.749) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.615) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.268) r2: (test=-5.620) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.084) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.152) r2: (test=0.230) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.106) r2: (test=-1.955) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.621) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.288) r2: (test=-6.672) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.347) r2: (test=-0.026) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.295) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.085) r2: (test=-0.873) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.604) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.271) r2: (test=-5.759) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.356) r2: (test=-0.075) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.294) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.082) r2: (test=-0.752) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.615) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.268) r2: (test=-5.622) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.084) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.294) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.082) r2: (test=-0.749) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.615) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.268) r2: (test=-5.620) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.084) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.294) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.082) r2: (test=-0.749) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.615) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.268) r2: (test=-5.620) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.084) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.146) r2: (test=0.294) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.082) r2: (test=-0.749) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.208) r2: (test=-3.615) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.268) r2: (test=-5.620) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.357) r2: (test=-0.084) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.0s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.120) r2: (test=0.522) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.063) r2: (test=-0.047) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.248) r2: (test=-5.516) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.333) r2: (test=-9.210) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.359) r2: (test=-0.094) total time=   0.4s\n"
     ]
    }
   ],
   "source": [
    "GS_xgb_milk.fit(xtrain_scale,ytrain_scale);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6103bcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "             gamma=0.1, gpu_id=-1, importance_type=None,\n",
      "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
      "             max_depth=3, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=340, n_jobs=4,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=2021,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# print best model\n",
    "print(GS_xgb_milk.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6537541a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model Parameters {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 340}\n",
      "Best model R2 score -1.9548865307455963\n"
     ]
    }
   ],
   "source": [
    "# print best parameters\n",
    "print('Best model Parameters',GS_xgb_milk.best_params_)\n",
    "# best score\n",
    "print('Best model R2 score',GS_xgb_milk.best_score_)\n",
    "\n",
    "# write the Grid Search results to csv to choose best model with least resource consumption\n",
    "GS_xgb_df_milk = pd.DataFrame(GS_xgb_milk.cv_results_)\n",
    "GS_xgb_df_milk = GS_xgb_df_milk.sort_values('rank_test_r2')\n",
    "#GS_xgb_df_milk.to_csv('./../artifacts/grid-search-xgb-milk-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e5642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "595f37de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28771797 0.28771797 0.28771797 0.28771797 0.28771797 0.28771797\n",
      " 0.28771797]\n",
      "[[36.8]\n",
      " [39.3]\n",
      " [25. ]\n",
      " [53.7]\n",
      " [27.9]\n",
      " [39.4]\n",
      " [49.5]]\n"
     ]
    }
   ],
   "source": [
    "print(GS_xgb_milk.predict(X_test))\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0459ab28",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f1441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade tensorflow\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(2021)\n",
    "#import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(1)\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d325597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501d4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input layers  = Number of features in the training set + 1\n",
    "model.add(Dense(24, input_dim=24, kernel_initializer='normal', activation='relu'))\n",
    "# hidden layers = Training Data Samples/Factor * (Input Neurons + Output Neurons)\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8179977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "history=model.fit(xtrain_scale, ytrain_scale, epochs=30, batch_size=150, verbose=1, validation_split=0.2)\n",
    "predictions = model.predict(xtest_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a136d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scaler_y.inverse_transform(predictions)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb8eb9",
   "metadata": {},
   "source": [
    "## ANN hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe4e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "!pip install keras-tuner\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6199a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model= keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers',2,23)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                           min_value=23,\n",
    "                                           max_value=600,\n",
    "                                           step=32),\n",
    "                              activation='relu'))\n",
    "        model.add(layers.Dense(1,activation='linear'))\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                hp.Choice('learning_rate',[1e-2,1e-3,1e-4])),\n",
    "        loss='mean_absolute_error',\n",
    "        metrics=['mean_absolute_error'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42b62c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 21:01:52.615371: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# create a directory to store each iteration of modelling\n",
    "tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_mean_absolute_error',\n",
    "        max_trials=5,\n",
    "        executions_per_trial=3,\n",
    "        directory='CA2',\n",
    "        project_name='Milk production forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb25c73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 23, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "# parameter space to search in\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c17e6889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 04s]\n",
      "val_mean_absolute_error: 0.06291941305001576\n",
      "\n",
      "Best val_mean_absolute_error So Far: 0.05973196029663086\n",
      "Total elapsed time: 00h 00m 24s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "tuner.search(xtrain_scale,ytrain_scale,epochs=20,validation_data=(xtest_scale,ytest_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "700e018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in CA2/Milk production forecast\n",
      "Showing 10 best trials\n",
      "Objective(name='val_mean_absolute_error', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 160\n",
      "learning_rate: 0.01\n",
      "Score: 0.05973196029663086\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 15\n",
      "units_0: 512\n",
      "learning_rate: 0.01\n",
      "Score: 0.06291941305001576\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 6\n",
      "units_0: 448\n",
      "learning_rate: 0.01\n",
      "Score: 0.06576412667830785\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 22\n",
      "units_0: 96\n",
      "learning_rate: 0.01\n",
      "Score: 0.10544607043266296\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 20\n",
      "units_0: 96\n",
      "learning_rate: 0.0001\n",
      "Score: 0.14712721357742944\n"
     ]
    }
   ],
   "source": [
    "# print best 10 models according to previously selected metric\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55c9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
