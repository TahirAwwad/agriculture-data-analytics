{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a36702",
   "metadata": {},
   "source": [
    "<!--\n",
    "import data_analytics.github as github\n",
    "print(github.create_jupyter_notebook_header(\"markcrowe-com\", \"agriculture-data-analytics\", \"notebooks/notebook-3-03-ml-milk-production.ipynb\", \"master\"))\n",
    "-->\n",
    "<table style=\"margin: auto;\"><tr><td><a href=\"https://mybinder.org/v2/gh/markcrowe-com/agriculture-data-analytics/master?filepath=notebooks/notebook-3-03-ml-milk-production.ipynb\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open In Binder\"/></a></td><td>online editors</td><td><a href=\"https://colab.research.google.com/github/markcrowe-com/agriculture-data-analytics/blob/master/notebooks/notebook-3-03-ml-milk-production.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce85eac6",
   "metadata": {},
   "source": [
    "# Objective\n",
    "       Create the best machine learning model to predict Milk production value in Ireland\n",
    "       according to the historical data from Central Statistics office CSO.\n",
    "       AEA01 Value at Current Prices for Output, Input and Income in Agriculture\n",
    "       Downloaded https://data.cso.ie/table/AEA01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a82bd75",
   "metadata": {},
   "source": [
    "# Contents\n",
    "    - Read data from Assets folder\n",
    "    - Split to training / testing sets\n",
    "    - Scale each set seperatly\n",
    "    - Run Models\n",
    "        - Define Hyper parameter tuning Cross Validation Grid or Random Search\n",
    "        - Random Forest Regressor\n",
    "        - XGBOOST Regressor\n",
    "        - ANN\n",
    "    - Save best model into Pickle file\n",
    "    - Next step: Deploy selected model on a Streamlit webapp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55902df1",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d65b56",
   "metadata": {},
   "source": [
    "Import required third party Python libraries, import supporting functions and sets up data source file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2782cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras-tuner\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Local\n",
    "#!pip install -r script/requirements.txt --quiet --user\n",
    "# Remote option\n",
    "#!pip install -r https://github.com/markcrowe-com/agriculture-data-analytics/blob/master/notebooks/script/requirements.txt --quiet --user\n",
    "#import data_analytics.exploratory_data_analysis as eda\n",
    "#import data_analytics.exploratory_data_analysis_reports as eda_reports\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39543089",
   "metadata": {},
   "source": [
    "### Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99092f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimensions \n",
      " (32, 57)\n",
      "\n",
      "\n",
      "Data sample\n",
      "     Unnamed: 0  Year          UNIT  Agricultural Output at Basic Prices  \\\n",
      "9            9  1999  Euro Million                               5651.4   \n",
      "28          28  2018  Euro Million                               8663.7   \n",
      "12          12  2002  Euro Million                               5836.1   \n",
      "21          21  2011  Euro Million                               6576.2   \n",
      "30          30  2020  Euro Million                               8908.3   \n",
      "\n",
      "    All Cereals  All Crops  All Livestock  All Livestock Products  \\\n",
      "9         164.1     1184.3         2067.9                  1438.1   \n",
      "28        288.4     2126.0         3431.4                  2639.2   \n",
      "12        141.9     1245.3         2014.8                  1451.0   \n",
      "21        290.1     1715.9         2644.8                  1891.1   \n",
      "30        289.5     1942.9         3591.8                  2832.0   \n",
      "\n",
      "    All Livestock Products - Milk  \\\n",
      "9                          1408.8   \n",
      "28                         2556.7   \n",
      "12                         1413.0   \n",
      "21                         1834.8   \n",
      "30                         2752.7   \n",
      "\n",
      "    All Livestock Products Other Products (excluding Milk)  ...  \\\n",
      "9                                                29.3       ...   \n",
      "28                                               82.6       ...   \n",
      "12                                               37.9       ...   \n",
      "21                                               56.3       ...   \n",
      "30                                               79.2       ...   \n",
      "\n",
      "    Livestock - Horses  Livestock - Pig  Livestock - Poultry  \\\n",
      "9                150.0            251.4                137.8   \n",
      "28               306.4            459.1                159.0   \n",
      "12               200.7            300.9                132.1   \n",
      "21               135.6            394.2                130.1   \n",
      "30               216.1            601.9                180.0   \n",
      "\n",
      "    Livestock - Sheep  Net Value Added at Basic Prices  Operating Surplus  \\\n",
      "9               198.0                           1973.9             1930.5   \n",
      "28              258.8                           1708.0             2823.0   \n",
      "12              202.2                           1786.8             2024.8   \n",
      "21              189.8                           1159.5             2515.8   \n",
      "30              303.3                           2233.8             3262.8   \n",
      "\n",
      "    Other Subsidies Less Taxes on Production  \\\n",
      "9                                      331.6   \n",
      "28                                    1682.8   \n",
      "12                                     616.1   \n",
      "21                                    1831.7   \n",
      "30                                    1646.5   \n",
      "\n",
      "    Subsidies less Taxes on Products  Subsidies on Products  Taxes on Products  \n",
      "9                              715.8                  743.7               27.9  \n",
      "28                              13.9                   65.1               51.2  \n",
      "12                             876.7                  904.1               27.4  \n",
      "21                             -11.0                   31.0               42.0  \n",
      "30                              94.6                  147.2               52.6  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./../artifacts/TA_inputoutputvalue_1990_2021_CSO.csv\")\n",
    "print(\"data dimensions \\n\",df.shape)\n",
    "print()\n",
    "#print(\"data column info \\n\",df.info)\n",
    "print()\n",
    "print('Data sample\\n',df.sample(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f762572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# create score dataframe to store model scores\n",
    "df_score = pd.DataFrame()\n",
    "print(df_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dce267",
   "metadata": {},
   "source": [
    "## Production of Milk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a096f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milk production dataset dimenssions \n",
      " (32, 7)\n",
      "Milk production dataset Sample \n",
      "       All Livestock Products - Milk  Taxes on Products  Subsidies on Products  \\\n",
      "Year                                                                            \n",
      "1990                         1316.3               75.0                  408.9   \n",
      "1991                         1258.9               78.2                  357.3   \n",
      "1992                         1373.1               79.5                  446.0   \n",
      "1993                         1439.0               68.0                  466.4   \n",
      "1994                         1446.2               53.7                  666.0   \n",
      "\n",
      "      Compensation of Employees  Contract Work  Entrepreneurial Income  \\\n",
      "Year                                                                     \n",
      "1990                      377.6          180.7                  1577.2   \n",
      "1991                      362.5          172.0                  1440.2   \n",
      "1992                      336.8          179.8                  1842.6   \n",
      "1993                      339.0          199.5                  1985.6   \n",
      "1994                      345.2          205.3                  2051.7   \n",
      "\n",
      "      Factor Income  \n",
      "Year                 \n",
      "1990         2321.1  \n",
      "1991         2136.5  \n",
      "1992         2516.2  \n",
      "1993         2586.9  \n",
      "1994         2623.7  \n"
     ]
    }
   ],
   "source": [
    "## Extract milk production dataset\n",
    "# drop redundunt columns\n",
    "df = df.drop('Unnamed: 0',axis = 1)\n",
    "\n",
    "# extract milk dataset\n",
    "df_milk = df[['Year',\n",
    "#              'UNIT',\n",
    "              'All Livestock Products - Milk',\n",
    "              'Taxes on Products',\n",
    "              'Subsidies on Products',\n",
    "              'Compensation of Employees',\n",
    "              'Contract Work',\n",
    "              'Entrepreneurial Income',\n",
    "              'Factor Income',\n",
    "              #'Fixed Capital Consumption - Farm Buildings',\n",
    "              #'Fixed Capital Consumption - Machinery, Equipment, etc',\n",
    "              #'Interest less FISIM',\n",
    "              #'Operating Surplus',\n",
    "              #'Livestock - Cattle',\n",
    "              #'Livestock - Sheep',\n",
    "              #'Land Rental',\n",
    "              #'Intermediate Consumption - Contract Work',\n",
    "              #'Intermediate Consumption - Crop Protection Products',\n",
    "              #'Intermediate Consumption - Energy and Lubricants',\n",
    "              #'Intermediate Consumption - Feeding Stuffs',\n",
    "              #'Intermediate Consumption - Fertilisers',\n",
    "              #'Intermediate Consumption - Financial Intermediation Services Indirect',\n",
    "              #'Intermediate Consumption - Forage Plants',\n",
    "              #'Intermediate Consumption - Maintenance and Repairs',\n",
    "              #'Intermediate Consumption - Seeds',\n",
    "              #'Intermediate Consumption - Services',\n",
    "              #'Intermediate Consumption - Veterinary Expenses',\n",
    "              #'Intermediate Consumption - Other Goods (Detergents, Small Tools, etc)',\n",
    "              #'Intermediate Consumption - Other Goods and Services'\n",
    "              \n",
    "             ]]\n",
    "# Assign year as index\n",
    "df_milk.set_index('Year',drop=True,inplace=True)\n",
    "\n",
    "print(\"Milk production dataset dimenssions \\n\", df_milk.shape)\n",
    "print(\"Milk production dataset Sample \\n\", df_milk.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a418fbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#eda_reports.print_dataframe_analysis_report(df_milk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b59fc",
   "metadata": {},
   "source": [
    "### Define 20% Training set 80% Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3fb066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features dimension  (32, 5)\n",
      "target dimension  (32, 1)\n",
      "\n",
      "x_train dimension  (25, 5)\n",
      "y_train dimension  (25, 1)\n",
      "\n",
      "x_test dimension  (7, 5)\n",
      "y_test dimension  (7, 1)\n"
     ]
    }
   ],
   "source": [
    "# define target & feature variables\n",
    "\n",
    "X = df_milk.iloc[:,2:].values\n",
    "Y = df_milk.iloc[:,1].values.reshape(-1,1)\n",
    "print('features dimension ',np.shape(X))\n",
    "print('target dimension ',np.shape(Y))\n",
    "\n",
    "# impute mean value for NA's\n",
    "#from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X = imp_mean.fit_transform(X)\n",
    "Y = imp_mean.fit_transform(Y)\n",
    "\n",
    "\n",
    "# split train test split 20\n",
    "X_train, X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=2021)\n",
    "print()\n",
    "print('x_train dimension ', X_train.shape)\n",
    "print('y_train dimension ', Y_train.shape)\n",
    "print()\n",
    "print('x_test dimension ', X_test.shape)\n",
    "print('y_test dimension ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefebdf9",
   "metadata": {},
   "source": [
    "### Scale & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8a1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale raining set and test set seperatly\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# calculate mean and std of training set \n",
    "scaler_x.fit(X_train)\n",
    "scaler_y.fit(Y_train)\n",
    "scaler_x.fit(X_test)\n",
    "scaler_y.fit(Y_test)\n",
    "\n",
    "# apply scaler to data set\n",
    "xtrain_scale = scaler_x.transform(X_train)\n",
    "ytrain_scale = scaler_y.transform(Y_train)\n",
    "\n",
    "xtest_scale = scaler_x.transform(X_test)\n",
    "ytest_scale = scaler_y.transform(Y_test)\n",
    "\n",
    "# fit and transform in one line\n",
    "# scaler_x.fit_transform(X_train)\n",
    "\n",
    "# remeber to inverse the scaling on model output\n",
    "# scaler_x.inverse_transform(xtest_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f58f53",
   "metadata": {},
   "source": [
    "### Model 1 RandomForest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3679f38c",
   "metadata": {},
   "source": [
    "#### Train RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe9bbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training model  RandomForestRegressor(criterion='absolute_error', n_estimators=500,\n",
      "                      random_state=2021)\n",
      "Best training model score, coefficient of determination R squared 0.034406025017006604\n"
     ]
    }
   ],
   "source": [
    "# define Random Forest Regressor\n",
    "rf_regressor_milk = RandomForestRegressor(random_state=2021)\n",
    "\n",
    "# define list of Parameters\n",
    "params_rf_milk = {'n_estimators':[100,500,800],\n",
    "                  'criterion':['squared_error', 'absolute_error', 'poisson'],\n",
    "                  'max_features':[\"auto\", \"sqrt\", \"log2\"],\n",
    "                  \"bootstrap\": [True, False]\n",
    "                   }\n",
    "\n",
    "# Hyper parameter tuning via Grid Search Cross Validation \n",
    "grid_rf_milk = GridSearchCV(estimator= rf_regressor_milk,\n",
    "                          param_grid= params_rf_milk,\n",
    "                          n_jobs=-1,\n",
    "                          cv=5\n",
    "                     )\n",
    "\n",
    "# Fit the grid to scaled data\n",
    "grid_rf_milk.fit(xtrain_scale,ytrain_scale.reshape(-1))\n",
    "\n",
    "# print best training model & R squared score\n",
    "print('Best training model ',grid_rf_milk.best_estimator_)\n",
    "print('Best training model score, coefficient of determination R squared', grid_rf_milk.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87382d4",
   "metadata": {},
   "source": [
    "#### Predict RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9f74e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted milk production values \n",
      " [[46.1244    ]\n",
      " [46.1494    ]\n",
      " [46.81763226]\n",
      " [60.703     ]\n",
      " [44.0322    ]\n",
      " [38.5768    ]\n",
      " [55.66569032]]\n",
      "actual milk production values \n",
      " [[36.8]\n",
      " [39.3]\n",
      " [25. ]\n",
      " [53.7]\n",
      " [27.9]\n",
      " [39.4]\n",
      " [49.5]]\n",
      "                Model  Score MAE\n",
      "Model 1  RandomForest   9.730789\n"
     ]
    }
   ],
   "source": [
    "# Predict Milk Production and unscale back to original values\n",
    "y_predict = scaler_y.inverse_transform(grid_rf_milk.predict(xtest_scale).reshape(-1, 1))\n",
    "\n",
    "print('predicted milk production values \\n',y_predict)\n",
    "print('actual milk production values \\n',Y_test)\n",
    "\n",
    "# Calculate Mean Absolute Error\n",
    "MAE_rf = mean_absolute_error(Y_test,y_predict)\n",
    "#print(MAE_rf)\n",
    "\n",
    "# add model score to Score Dataframe\n",
    "df_score = pd.DataFrame(data={'Model':'RandomForest',\n",
    "                           'Score MAE':MAE_rf},index=['Model 1'])\n",
    "\n",
    "print(df_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aab677",
   "metadata": {},
   "source": [
    "### Model 2 XGBOOST Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb497c7",
   "metadata": {},
   "source": [
    "#### Train XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "119a7167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.447) r2: (test=-0.556) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.316) r2: (test=-1.202) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-1.452) r2: (test=-0.512) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.430) r2: (test=-0.438) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.758) r2: (test=-4.159) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.244) r2: (test=-0.306) total time=   0.7s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.629) r2: (test=-0.109) total time=   1.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-1.332) r2: (test=-0.272) total time=   1.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.260) r2: (test=-0.487) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.656) r2: (test=-0.206) total time=   1.0s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-1.366) r2: (test=-0.340) total time=   0.8s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.361) r2: (test=-0.015) total time=   1.6s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.783) r2: (test=-4.504) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.733) r2: (test=-0.507) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-1.415) r2: (test=-0.436) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.381) r2: (test=-0.131) total time=   1.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.639) r2: (test=-2.665) total time=   1.6s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.355) r2: (test=0.019) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.531) r2: (test=0.208) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.634) r2: (test=-2.606) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.489) r2: (test=0.328) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-1.204) r2: (test=-0.039) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.380) r2: (test=-0.121) total time=   1.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.460) r2: (test=-0.900) total time=   1.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.731) r2: (test=-3.795) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-1.403) r2: (test=-0.412) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.203) r2: (test=0.092) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.373) r2: (test=-0.085) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.524) r2: (test=0.229) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.329) r2: (test=0.159) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.293) r2: (test=0.334) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.495) r2: (test=-1.199) total time=   1.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.673) r2: (test=-8.959) total time=   1.7s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.716) r2: (test=-0.436) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.245) r2: (test=-0.322) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.731) r2: (test=-3.795) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.401) r2: (test=-0.253) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-1.403) r2: (test=-0.412) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.633) r2: (test=-0.124) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.660) r2: (test=-2.913) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-1.352) r2: (test=-0.312) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.203) r2: (test=0.092) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.329) r2: (test=0.159) total time=   0.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.349) r2: (test=-1.675) total time=   0.6s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-1.201) r2: (test=-0.035) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.272) r2: (test=0.425) total time=   1.6s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.483) r2: (test=-1.095) total time=   2.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.414) r2: (test=-2.763) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.378) r2: (test=-0.114) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.391) r2: (test=0.571) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.464) r2: (test=-0.932) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-1.155) r2: (test=0.043) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.622) r2: (test=-7.509) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.394) r2: (test=-0.207) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.388) r2: (test=0.578) total time=   0.8s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.394) r2: (test=-0.209) total time=   0.8s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.623) r2: (test=-7.530) total time=   0.9s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.623) r2: (test=-7.530) total time=   1.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.367) r2: (test=0.623) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.470) r2: (test=-3.858) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.524) r2: (test=-1.461) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.289) r2: (test=0.349) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-1.179) r2: (test=0.003) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.575) r2: (test=-6.264) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-1.155) r2: (test=0.043) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.471) r2: (test=-0.994) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.646) r2: (test=-8.183) total time=   0.6s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-1.151) r2: (test=0.050) total time=   0.6s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.278) r2: (test=0.400) total time=   1.5s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.470) r2: (test=-0.986) total time=   2.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.295) r2: (test=0.755) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.483) r2: (test=-1.098) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-1.155) r2: (test=0.043) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.658) r2: (test=-8.512) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.470) r2: (test=-0.986) total time=   0.8s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.658) r2: (test=-8.536) total time=   1.7s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-1.151) r2: (test=0.050) total time=   1.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.278) r2: (test=0.400) total time=   2.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.654) r2: (test=-2.843) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.370) r2: (test=0.615) total time=   0.8s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-1.161) r2: (test=0.033) total time=   0.9s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.465) r2: (test=-0.680) total time=   1.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.343) r2: (test=-0.053) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.532) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.590) r2: (test=-1.706) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.343) r2: (test=-0.053) total time=   0.8s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.547) r2: (test=-5.571) total time=   1.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.532) total time=   2.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   2.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.590) r2: (test=-1.706) total time=   0.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.343) r2: (test=-0.053) total time=   1.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.547) r2: (test=-5.571) total time=   2.4s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.784) r2: (test=-0.724) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.813) r2: (test=-4.939) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-1.458) r2: (test=-0.526) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.316) r2: (test=-1.202) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.440) r2: (test=-0.508) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.756) r2: (test=-0.602) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.789) r2: (test=-4.585) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.725) r2: (test=-0.474) total time=   0.7s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-1.415) r2: (test=-0.436) total time=   0.5s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.708) r2: (test=-3.498) total time=   1.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.219) r2: (test=-0.060) total time=   1.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.792) r2: (test=-0.757) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.784) r2: (test=-0.725) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.772) r2: (test=-0.672) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.756) r2: (test=-0.604) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.726) r2: (test=-0.478) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-1.415) r2: (test=-0.436) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.370) r2: (test=-0.064) total time=   0.8s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.677) r2: (test=-3.117) total time=   1.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-1.458) r2: (test=-0.526) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.313) r2: (test=-1.156) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.440) r2: (test=-0.507) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.772) r2: (test=-0.669) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.428) r2: (test=-0.428) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.409) r2: (test=-0.302) total time=   0.5s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.680) r2: (test=-3.149) total time=   1.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.200) r2: (test=0.122) total time=   1.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.792) r2: (test=-0.757) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.323) r2: (test=-1.299) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.812) r2: (test=-4.917) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.446) r2: (test=-0.551) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-1.458) r2: (test=-0.526) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.786) r2: (test=-0.732) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.802) r2: (test=-4.775) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-1.452) r2: (test=-0.512) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.294) r2: (test=-0.900) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-1.439) r2: (test=-0.486) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.260) r2: (test=-0.487) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.656) r2: (test=-0.206) total time=   1.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.602) r2: (test=-0.017) total time=   1.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-1.332) r2: (test=-0.272) total time=   1.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.366) r2: (test=-0.040) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.475) r2: (test=-1.027) total time=   1.3s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.496) r2: (test=-4.407) total time=   2.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.716) r2: (test=-0.436) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.245) r2: (test=-0.322) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.401) r2: (test=-0.253) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.633) r2: (test=-0.124) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.660) r2: (test=-2.913) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-1.352) r2: (test=-0.312) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.596) r2: (test=-2.186) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.393) r2: (test=0.567) total time=   0.6s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-1.201) r2: (test=-0.035) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.272) r2: (test=0.425) total time=   1.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.483) r2: (test=-1.095) total time=   1.8s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.203) r2: (test=0.092) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.373) r2: (test=-0.085) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.524) r2: (test=0.230) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.596) r2: (test=-2.186) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.394) r2: (test=0.564) total time=   0.6s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.591) r2: (test=-6.690) total time=   1.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-1.161) r2: (test=0.032) total time=   1.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.273) r2: (test=0.418) total time=   2.6s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.623) r2: (test=-7.530) total time=   0.7s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-1.153) r2: (test=0.046) total time=   0.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.452) r2: (test=-0.835) total time=   0.9s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.388) r2: (test=0.578) total time=   1.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-1.153) r2: (test=0.046) total time=   1.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.292) r2: (test=0.761) total time=   0.7s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.292) r2: (test=0.761) total time=   1.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-1.151) r2: (test=0.050) total time=   1.6s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.278) r2: (test=0.400) total time=   2.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.471) r2: (test=-0.994) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.288) r2: (test=0.768) total time=   0.9s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-1.151) r2: (test=0.050) total time=   0.7s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.278) r2: (test=0.400) total time=   1.6s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.470) r2: (test=-0.986) total time=   2.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.654) r2: (test=-2.843) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-1.161) r2: (test=0.033) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.806) r2: (test=-13.280) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.465) r2: (test=-0.680) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.370) r2: (test=0.615) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.654) r2: (test=-2.843) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-1.161) r2: (test=0.033) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.806) r2: (test=-13.280) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-1.161) r2: (test=0.033) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.654) r2: (test=-2.843) total time=   0.8s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.806) r2: (test=-13.280) total time=   1.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.532) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.547) r2: (test=-5.571) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.343) r2: (test=-0.053) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.590) r2: (test=-1.706) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.532) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.590) r2: (test=-1.706) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.547) r2: (test=-5.571) total time=   0.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.590) r2: (test=-1.706) total time=   0.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.343) r2: (test=-0.053) total time=   1.6s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.547) r2: (test=-5.571) total time=   2.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.532) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.547) r2: (test=-5.571) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.343) r2: (test=-0.053) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.590) r2: (test=-1.706) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.532) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.343) r2: (test=-0.053) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.547) r2: (test=-5.571) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.343) r2: (test=-0.053) total time=   0.8s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.547) r2: (test=-5.571) total time=   1.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.532) total time=   1.9s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   3.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.360) r2: (test=-0.011) total time=   0.9s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.682) r2: (test=-3.176) total time=   1.3s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.446) r2: (test=-0.547) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.786) r2: (test=-0.731) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.802) r2: (test=-4.776) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.813) r2: (test=-4.938) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.805) r2: (test=-4.815) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.301) r2: (test=-0.998) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-1.439) r2: (test=-0.486) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.410) r2: (test=-0.307) total time=   0.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.706) r2: (test=-3.475) total time=   0.8s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.229) r2: (test=-0.154) total time=   1.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.792) r2: (test=-0.757) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.323) r2: (test=-1.299) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.812) r2: (test=-4.917) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-0.446) r2: (test=-0.551) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.786) r2: (test=-0.732) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.802) r2: (test=-4.775) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-1.452) r2: (test=-0.512) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.783) r2: (test=-4.504) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.733) r2: (test=-0.507) total time=   0.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-1.415) r2: (test=-0.436) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.381) r2: (test=-0.131) total time=   1.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.639) r2: (test=-2.665) total time=   1.6s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.313) r2: (test=-1.156) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.440) r2: (test=-0.507) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.772) r2: (test=-0.669) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.428) r2: (test=-0.428) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.748) r2: (test=-4.017) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.680) r2: (test=-3.149) total time=   1.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.200) r2: (test=0.122) total time=   1.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.712) r2: (test=-0.423) total time=   0.0s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.271) r2: (test=-0.617) total time=   0.0s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.744) r2: (test=-3.965) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.396) r2: (test=-0.220) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-1.403) r2: (test=-0.412) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.653) r2: (test=-0.197) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.236) r2: (test=-0.228) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.695) r2: (test=-3.332) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-1.352) r2: (test=-0.312) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.241) r2: (test=-0.281) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-1.282) r2: (test=-0.179) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.542) r2: (test=-1.638) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.457) r2: (test=-3.598) total time=   0.9s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.387) r2: (test=0.580) total time=   2.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-1.143) r2: (test=0.062) total time=   1.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.349) r2: (test=-1.684) total time=   0.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.299) r2: (test=0.749) total time=   1.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-1.161) r2: (test=0.032) total time=   1.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.273) r2: (test=0.418) total time=   1.8s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-1.278) r2: (test=-0.173) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.536) r2: (test=-1.580) total time=   0.6s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.299) r2: (test=0.748) total time=   1.5s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.282) r2: (test=0.777) total time=   2.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-1.154) r2: (test=0.044) total time=   3.6s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.394) r2: (test=-0.209) total time=   0.9s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.452) r2: (test=-0.835) total time=   1.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.298) r2: (test=0.750) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.483) r2: (test=-1.098) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.292) r2: (test=0.762) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.278) r2: (test=0.400) total time=   0.6s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.646) r2: (test=-8.183) total time=   1.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.292) r2: (test=0.761) total time=   2.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.364) r2: (test=0.628) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.467) r2: (test=-3.800) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.524) r2: (test=-1.461) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-0.289) r2: (test=0.349) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-1.179) r2: (test=0.003) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.587) r2: (test=-6.583) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.270) r2: (test=0.431) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.287) r2: (test=0.768) total time=   0.5s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.277) r2: (test=0.402) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.658) r2: (test=-8.536) total time=   0.8s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.288) r2: (test=0.768) total time=   1.8s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.288) r2: (test=0.768) total time=   2.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-1.151) r2: (test=0.050) total time=   2.9s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.465) r2: (test=-0.680) total time=   0.8s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.654) r2: (test=-2.843) total time=   1.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=20; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.547) r2: (test=-5.571) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.343) r2: (test=-0.053) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.547) r2: (test=-5.571) total time=   0.8s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.532) total time=   1.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   1.7s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.590) r2: (test=-1.706) total time=   2.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.343) r2: (test=-0.053) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.532) total time=   0.7s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   0.7s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.590) r2: (test=-1.706) total time=   1.4s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.343) r2: (test=-0.053) total time=   2.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.325) r2: (test=-1.320) total time=   0.0s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.447) r2: (test=-0.553) total time=   0.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.772) r2: (test=-0.671) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.805) r2: (test=-4.817) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-1.452) r2: (test=-0.512) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.301) r2: (test=-0.994) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.428) r2: (test=-0.425) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.277) r2: (test=-0.682) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.406) r2: (test=-0.281) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.238) r2: (test=-0.245) total time=   1.0s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.625) r2: (test=-0.095) total time=   1.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-1.335) r2: (test=-0.278) total time=   1.7s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.402) r2: (test=-0.261) total time=   0.7s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.206) r2: (test=0.064) total time=   1.1s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-1.368) r2: (test=-0.343) total time=   0.9s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.345) r2: (test=0.071) total time=   2.0s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.783) r2: (test=-4.507) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.732) r2: (test=-0.503) total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.325) r2: (test=-1.320) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-1.458) r2: (test=-0.526) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.441) r2: (test=-0.515) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.789) r2: (test=-4.582) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.279) r2: (test=-0.710) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.670) r2: (test=-0.259) total time=   0.8s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-1.366) r2: (test=-0.340) total time=   0.8s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.337) r2: (test=0.118) total time=   1.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.294) r2: (test=-0.900) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-1.439) r2: (test=-0.486) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.748) r2: (test=-4.017) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.210) r2: (test=0.027) total time=   0.9s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.602) r2: (test=-0.017) total time=   1.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-1.332) r2: (test=-0.272) total time=   1.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.409) r2: (test=-0.302) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.210) r2: (test=0.027) total time=   0.9s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-1.366) r2: (test=-0.340) total time=   0.8s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.361) r2: (test=-0.015) total time=   1.6s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.314) r2: (test=0.234) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.370) r2: (test=-2.016) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.402) r2: (test=0.547) total time=   0.8s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-1.152) r2: (test=0.047) total time=   2.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.389) r2: (test=-0.175) total time=   1.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.203) r2: (test=0.092) total time=   0.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-1.278) r2: (test=-0.173) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.536) r2: (test=-1.580) total time=   0.6s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.592) r2: (test=-6.697) total time=   1.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.282) r2: (test=0.778) total time=   1.8s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-1.154) r2: (test=0.044) total time=   1.8s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.293) r2: (test=0.334) total time=   0.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.495) r2: (test=-1.199) total time=   1.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.01, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.673) r2: (test=-8.968) total time=   2.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.454) r2: (test=0.421) total time=   0.1s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.496) r2: (test=-1.204) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-1.179) r2: (test=0.003) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.567) r2: (test=-6.075) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.387) r2: (test=-0.167) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.388) r2: (test=0.577) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.453) r2: (test=-0.843) total time=   0.4s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-1.153) r2: (test=0.046) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.452) r2: (test=-0.835) total time=   0.7s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.388) r2: (test=0.578) total time=   1.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-1.153) r2: (test=0.046) total time=   0.8s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.394) r2: (test=-0.209) total time=   1.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=40; neg_root_mean_squared_error: (test=-0.270) r2: (test=0.431) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.645) r2: (test=-8.158) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.277) r2: (test=0.402) total time=   0.3s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.470) r2: (test=-0.986) total time=   0.7s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.470) r2: (test=-0.986) total time=   1.5s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.646) r2: (test=-8.183) total time=   2.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=0.1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-1.151) r2: (test=0.050) total time=   2.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.278) r2: (test=0.400) total time=   0.8s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.470) r2: (test=-0.986) total time=   1.7s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=0.1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.658) r2: (test=-8.536) total time=   2.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.370) r2: (test=0.615) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.806) r2: (test=-13.280) total time=   0.1s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=20; neg_root_mean_squared_error: (test=-0.465) r2: (test=-0.680) total time=   0.1s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.370) r2: (test=0.615) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-0.654) r2: (test=-2.843) total time=   0.1s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=40; neg_root_mean_squared_error: (test=-1.161) r2: (test=0.033) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.806) r2: (test=-13.280) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-0.465) r2: (test=-0.680) total time=   0.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.370) r2: (test=0.615) total time=   0.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.465) r2: (test=-0.680) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.806) r2: (test=-13.280) total time=   0.8s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.370) r2: (test=0.615) total time=   1.2s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-1.161) r2: (test=0.033) total time=   1.3s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.532) total time=   0.7s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   0.7s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.590) r2: (test=-1.706) total time=   1.6s\n",
      "[CV 3/5] END gamma=0.01, learning_rate=1, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.343) r2: (test=-0.053) total time=   2.5s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=20; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   0.1s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.547) r2: (test=-5.571) total time=   0.2s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=40; neg_root_mean_squared_error: (test=-0.590) r2: (test=-1.706) total time=   0.2s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.532) total time=   0.3s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-0.590) r2: (test=-1.706) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.547) r2: (test=-5.571) total time=   0.8s\n",
      "[CV 1/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.409) r2: (test=0.532) total time=   1.3s\n",
      "[CV 5/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-1.150) r2: (test=0.051) total time=   1.4s\n",
      "[CV 4/5] END gamma=0.01, learning_rate=1, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.590) r2: (test=-1.706) total time=   2.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-1.439) r2: (test=-0.486) total time=   0.6s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.759) r2: (test=-4.167) total time=   0.4s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.667) r2: (test=-0.248) total time=   1.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-1.368) r2: (test=-0.343) total time=   0.8s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.329) r2: (test=0.155) total time=   1.4s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-0.294) r2: (test=-0.907) total time=   0.6s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=80; neg_root_mean_squared_error: (test=-1.439) r2: (test=-0.486) total time=   0.2s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.260) r2: (test=-0.483) total time=   0.7s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.653) r2: (test=-0.197) total time=   1.3s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.597) r2: (test=-0.001) total time=   1.9s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-1.335) r2: (test=-0.278) total time=   1.3s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=160; neg_root_mean_squared_error: (test=-0.748) r2: (test=-4.025) total time=   0.5s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-0.206) r2: (test=0.064) total time=   1.2s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=340; neg_root_mean_squared_error: (test=-1.368) r2: (test=-0.343) total time=   1.4s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=500; neg_root_mean_squared_error: (test=-0.345) r2: (test=0.071) total time=   2.5s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=80; neg_root_mean_squared_error: (test=-1.287) r2: (test=-0.188) total time=   0.2s\n",
      "[CV 3/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=160; neg_root_mean_squared_error: (test=-0.548) r2: (test=-1.690) total time=   0.4s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=340; neg_root_mean_squared_error: (test=-0.416) r2: (test=-2.801) total time=   0.8s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-0.400) r2: (test=0.552) total time=   1.3s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=500; neg_root_mean_squared_error: (test=-1.170) r2: (test=0.018) total time=   1.4s\n",
      "[CV 2/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=160; neg_root_mean_squared_error: (test=-0.223) r2: (test=-0.091) total time=   0.6s\n",
      "[CV 1/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-0.296) r2: (test=0.754) total time=   1.4s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=340; neg_root_mean_squared_error: (test=-1.176) r2: (test=0.008) total time=   1.6s\n",
      "[CV 4/5] END gamma=0.1, learning_rate=0.01, max_depth=6, n_estimators=500; neg_root_mean_squared_error: (test=-0.308) r2: (test=0.259) total time=   3.6s\n",
      "[CV 5/5] END gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=80; neg_root_mean_squared_error: (test=-1.287) r2: (test=-0.188) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training model  XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "             gamma=0.1, gpu_id=-1, importance_type=None,\n",
      "             interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
      "             max_depth=6, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=160, n_jobs=4,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=2021,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Best model Parameters {'gamma': 0.1, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 160}\n",
      "Best training model score, coefficient of determination R squared -0.15271282786267798\n"
     ]
    }
   ],
   "source": [
    "# define XGBRegressor\n",
    "xgb_regressor_milk = XGBRegressor(random_state=2021)\n",
    "\n",
    "# define parameters space to loop over\n",
    "params_xgb_milk = {'n_estimators':[20,40,80,160,340,500],\n",
    "             'max_depth':[3,6,9],\n",
    "             'gamma':[0.01,0.1],\n",
    "             'learning_rate':[0.001,0.01,0.1,1]\n",
    "             }\n",
    "\n",
    "# Hyper parameter tuning via Grid Search Cross Validation \n",
    "grid_xgb_milk = GridSearchCV(estimator=xgb_regressor_milk,\n",
    "                     param_grid=params_xgb_milk,\n",
    "                     #n_jobs=-1,\n",
    "                     scoring=['r2','neg_root_mean_squared_error'],\n",
    "                     refit= 'r2',\n",
    "                     n_jobs=-1,\n",
    "                     cv=5,\n",
    "                     verbose=4\n",
    "                     )\n",
    "\n",
    "# fit grid to training scaled set\n",
    "grid_xgb_milk.fit(xtrain_scale,ytrain_scale);\n",
    "\n",
    "\n",
    "# print best training model & R squared score\n",
    "print('Best training model ',grid_xgb_milk.best_estimator_)\n",
    "print('Best model Parameters',grid_xgb_milk.best_params_)\n",
    "print('Best training model score, coefficient of determination R squared', grid_xgb_milk.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f00fdb",
   "metadata": {},
   "source": [
    "#### Predict XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd170cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted milk production values \n",
      " [[45.5861  ]\n",
      " [45.99256 ]\n",
      " [50.727455]\n",
      " [59.506348]\n",
      " [50.727455]\n",
      " [35.886517]\n",
      " [48.685654]]\n",
      "actual milk production values \n",
      " [[36.8]\n",
      " [39.3]\n",
      " [25. ]\n",
      " [53.7]\n",
      " [27.9]\n",
      " [39.4]\n",
      " [49.5]]\n",
      "                Model  Score MAE\n",
      "Model 1  RandomForest   9.730789\n",
      "Model 2       XGBOOST  10.595393\n"
     ]
    }
   ],
   "source": [
    "# Predict Milk Production and unscale back to original values\n",
    "y_predict = scaler_y.inverse_transform(grid_xgb_milk.predict(xtest_scale).reshape(-1, 1))\n",
    "\n",
    "print('predicted milk production values \\n',y_predict)\n",
    "print('actual milk production values \\n',Y_test)\n",
    "\n",
    "# Calculate Mean Absolute Error\n",
    "MAE_xgb = mean_absolute_error(Y_test,y_predict)\n",
    "#print(MAE_xgb)\n",
    "\n",
    "# add model score to Score Dataframe\n",
    "df_score = pd.DataFrame(data = {'Model':['RandomForest','XGBOOST'],\n",
    "                                'Score MAE': [MAE_rf,MAE_xgb]},\n",
    "                        index=['Model 1','Model 2'])\n",
    "\n",
    "print(df_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6537541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the Grid Search results to csv to choose best model with least resource consumption\n",
    "\n",
    "#GS_xgb_df_milk = pd.DataFrame(GS_xgb_milk.cv_results_)\n",
    "#GS_xgb_df_milk = GS_xgb_df_milk.sort_values('rank_test_r2')\n",
    "#GS_xgb_df_milk.to_csv('./../artifacts/grid-search-xgb-milk-results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb8eb9",
   "metadata": {},
   "source": [
    "## ANN Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30620b25",
   "metadata": {},
   "source": [
    "#### Training & Keras Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6199a6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 12s]\n",
      "val_mean_absolute_error: 0.38478166858355206\n",
      "\n",
      "Best val_mean_absolute_error So Far: 0.2196421374877294\n",
      "Total elapsed time: 00h 00m 58s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "\n",
      "Results summary\n",
      "Results in ANN-tuner/Milk production\n",
      "Showing 10 best trials\n",
      "Objective(name='val_mean_absolute_error', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 5\n",
      "units_0: 55\n",
      "learning_rate: 0.01\n",
      "Score: 0.2196421374877294\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 215\n",
      "learning_rate: 0.0001\n",
      "Score: 0.34854452808698017\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 22\n",
      "units_0: 311\n",
      "learning_rate: 0.0001\n",
      "Score: 0.38017324606577557\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 15\n",
      "units_0: 279\n",
      "learning_rate: 0.0001\n",
      "Score: 0.383053998152415\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 119\n",
      "learning_rate: 0.0001\n",
      "Score: 0.38478166858355206\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 0.4311 - mean_absolute_error: 0.4311 - val_loss: 0.2170 - val_mean_absolute_error: 0.2170\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4261 - mean_absolute_error: 0.4261 - val_loss: 0.2265 - val_mean_absolute_error: 0.2265\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4207 - mean_absolute_error: 0.4207 - val_loss: 0.2310 - val_mean_absolute_error: 0.2310\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4115 - mean_absolute_error: 0.4115 - val_loss: 0.2298 - val_mean_absolute_error: 0.2298\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3992 - mean_absolute_error: 0.3992 - val_loss: 0.2271 - val_mean_absolute_error: 0.2271\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3853 - mean_absolute_error: 0.3853 - val_loss: 0.2245 - val_mean_absolute_error: 0.2245\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3688 - mean_absolute_error: 0.3688 - val_loss: 0.2278 - val_mean_absolute_error: 0.2278\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3522 - mean_absolute_error: 0.3522 - val_loss: 0.2456 - val_mean_absolute_error: 0.2456\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3494 - mean_absolute_error: 0.3494 - val_loss: 0.2749 - val_mean_absolute_error: 0.2749\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3415 - mean_absolute_error: 0.3415 - val_loss: 0.3148 - val_mean_absolute_error: 0.3148\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3310 - mean_absolute_error: 0.3310 - val_loss: 0.3517 - val_mean_absolute_error: 0.3517\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3219 - mean_absolute_error: 0.3219 - val_loss: 0.3718 - val_mean_absolute_error: 0.3718\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3172 - mean_absolute_error: 0.3172 - val_loss: 0.3608 - val_mean_absolute_error: 0.3608\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3052 - mean_absolute_error: 0.3052 - val_loss: 0.3373 - val_mean_absolute_error: 0.3373\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2948 - mean_absolute_error: 0.2948 - val_loss: 0.3106 - val_mean_absolute_error: 0.3106\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2892 - mean_absolute_error: 0.2892 - val_loss: 0.3085 - val_mean_absolute_error: 0.3085\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2837 - mean_absolute_error: 0.2837 - val_loss: 0.3214 - val_mean_absolute_error: 0.3214\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2771 - mean_absolute_error: 0.2771 - val_loss: 0.3433 - val_mean_absolute_error: 0.3433\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2771 - mean_absolute_error: 0.2771 - val_loss: 0.3435 - val_mean_absolute_error: 0.3435\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2732 - mean_absolute_error: 0.2732 - val_loss: 0.3197 - val_mean_absolute_error: 0.3197\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2676 - mean_absolute_error: 0.2676 - val_loss: 0.2929 - val_mean_absolute_error: 0.2929\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2715 - mean_absolute_error: 0.2715 - val_loss: 0.3043 - val_mean_absolute_error: 0.3043\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2660 - mean_absolute_error: 0.2660 - val_loss: 0.3316 - val_mean_absolute_error: 0.3316\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2631 - mean_absolute_error: 0.2631 - val_loss: 0.3430 - val_mean_absolute_error: 0.3430\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2652 - mean_absolute_error: 0.2652 - val_loss: 0.3340 - val_mean_absolute_error: 0.3340\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2610 - mean_absolute_error: 0.2610 - val_loss: 0.3070 - val_mean_absolute_error: 0.3070\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2571 - mean_absolute_error: 0.2571 - val_loss: 0.2918 - val_mean_absolute_error: 0.2918\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2586 - mean_absolute_error: 0.2586 - val_loss: 0.3092 - val_mean_absolute_error: 0.3092\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2513 - mean_absolute_error: 0.2513 - val_loss: 0.3205 - val_mean_absolute_error: 0.3205\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2534 - mean_absolute_error: 0.2534 - val_loss: 0.3130 - val_mean_absolute_error: 0.3130\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2504 - mean_absolute_error: 0.2504 - val_loss: 0.2996 - val_mean_absolute_error: 0.2996\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2487 - mean_absolute_error: 0.2487 - val_loss: 0.3073 - val_mean_absolute_error: 0.3073\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2454 - mean_absolute_error: 0.2454 - val_loss: 0.3247 - val_mean_absolute_error: 0.3247\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2448 - mean_absolute_error: 0.2448 - val_loss: 0.3249 - val_mean_absolute_error: 0.3249\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2419 - mean_absolute_error: 0.2419 - val_loss: 0.3100 - val_mean_absolute_error: 0.3100\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2443 - mean_absolute_error: 0.2443 - val_loss: 0.3156 - val_mean_absolute_error: 0.3156\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2418 - mean_absolute_error: 0.2418 - val_loss: 0.3397 - val_mean_absolute_error: 0.3397\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2375 - mean_absolute_error: 0.2375 - val_loss: 0.3361 - val_mean_absolute_error: 0.3361\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2347 - mean_absolute_error: 0.2347 - val_loss: 0.3046 - val_mean_absolute_error: 0.3046\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2368 - mean_absolute_error: 0.2368 - val_loss: 0.2959 - val_mean_absolute_error: 0.2959\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2355 - mean_absolute_error: 0.2355 - val_loss: 0.3195 - val_mean_absolute_error: 0.3195\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2299 - mean_absolute_error: 0.2299 - val_loss: 0.3352 - val_mean_absolute_error: 0.3352\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2294 - mean_absolute_error: 0.2294 - val_loss: 0.3312 - val_mean_absolute_error: 0.3312\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2246 - mean_absolute_error: 0.2246 - val_loss: 0.3014 - val_mean_absolute_error: 0.3014\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2302 - mean_absolute_error: 0.2302 - val_loss: 0.3059 - val_mean_absolute_error: 0.3059\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2293 - mean_absolute_error: 0.2293 - val_loss: 0.3286 - val_mean_absolute_error: 0.3286\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2249 - mean_absolute_error: 0.2249 - val_loss: 0.3459 - val_mean_absolute_error: 0.3459\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2247 - mean_absolute_error: 0.2247 - val_loss: 0.3211 - val_mean_absolute_error: 0.3211\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2189 - mean_absolute_error: 0.2189 - val_loss: 0.3000 - val_mean_absolute_error: 0.3000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2203 - mean_absolute_error: 0.2203 - val_loss: 0.3012 - val_mean_absolute_error: 0.3012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16f0618d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define ANN model with Hyper paramter variable \n",
    "def build_model(hp):\n",
    "    model= keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers',2,23)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                           min_value=23,\n",
    "                                           max_value=600,\n",
    "                                           step=32),\n",
    "                              activation='relu'))\n",
    "        model.add(layers.Dense(1,activation='linear'))\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                hp.Choice('learning_rate',[1e-2,1e-3,1e-4])),\n",
    "        loss='mean_absolute_error',\n",
    "        metrics=['mean_absolute_error'])\n",
    "        return model\n",
    "    \n",
    "# create a directory to store each iteration of modelling\n",
    "tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_mean_absolute_error',\n",
    "        max_trials=5,\n",
    "        executions_per_trial=3,\n",
    "        directory='ANN-tuner',\n",
    "        project_name='Milk production')\n",
    "\n",
    "# Defined parameter space to search in\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# train trial models and compare with validation set\n",
    "tuner.search(xtrain_scale,ytrain_scale,epochs=50,validation_data=(xtest_scale,ytest_scale))\n",
    "\n",
    "# print best 10 models according to val_mean_absolute_error\n",
    "print('\\n')\n",
    "tuner.results_summary()\n",
    "\n",
    "# get best model from training trials\n",
    "bestANNModel = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# fit best model to training scaled data and scaled test data\n",
    "bestANNModel.fit(xtrain_scale,ytrain_scale,epochs=50,validation_data=(xtest_scale,ytest_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "700e018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted milk production values \n",
      " [[54.641827]\n",
      " [46.304825]\n",
      " [30.681519]\n",
      " [61.56327 ]\n",
      " [37.969273]\n",
      " [44.04872 ]\n",
      " [56.90565 ]]\n",
      "actual milk production values \n",
      " [[36.8]\n",
      " [39.3]\n",
      " [25. ]\n",
      " [53.7]\n",
      " [27.9]\n",
      " [39.4]\n",
      " [49.5]]\n",
      "                Model  Score MAE\n",
      "Model 1  RandomForest   9.730789\n",
      "Model 2       XGBOOST  10.595393\n",
      "Model 3           ANN   8.645012\n"
     ]
    }
   ],
   "source": [
    "# Predict Milk Production and unscale back to original values\n",
    "y_predict = scaler_y.inverse_transform(bestANNModel.predict(xtest_scale).reshape(-1, 1))\n",
    "\n",
    "print('predicted milk production values \\n',y_predict)\n",
    "print('actual milk production values \\n',Y_test)\n",
    "\n",
    "# Calculate Mean Absolute Error\n",
    "MAE_ANN = mean_absolute_error(Y_test,y_predict)\n",
    "#print(MAE_xgb)\n",
    "\n",
    "# add model score to Score Dataframe\n",
    "df_score = pd.DataFrame(data = {'Model':['RandomForest','XGBOOST','ANN'],\n",
    "                                'Score MAE': [MAE_rf,MAE_xgb,MAE_ANN]},\n",
    "                        index=['Model 1','Model 2','Model 3'])\n",
    "\n",
    "print(df_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808542b",
   "metadata": {},
   "source": [
    "# Pickle file\n",
    "    Save trained model into binary pickle file to use the model later with new input data from web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51778cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump/write Scaler into binary pickle\n",
    "pickle.dump(scaler_x,open('./../artifacts/pkl_scaler_x','wb'))\n",
    "\n",
    "# Read pickle file into variable to use scaler\n",
    "scaler_x_pkl_ann = pickle.load(open('./../artifacts/pkl_scaler_x','rb'))\n",
    "\n",
    "# Dump/write Scaler into binary pickle\n",
    "pickle.dump(scaler_y,open('./../artifacts/pkl_scaler_y','wb'))\n",
    "\n",
    "# Read pickle file into variable to use scaler\n",
    "scaler_y_pkl_ann = pickle.load(open('./../artifacts/pkl_scaler_y','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8488cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-23 20:20:52.949246: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://dd48629e-37e5-4c70-8d36-777b7b4c6a5b/assets\n",
      "\n",
      " Expected Milk Production is  76.89205\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dump/write model into binary pickle file in the current notebook directory\n",
    "pickle.dump(bestANNModel,open('./../artifacts/pkl_ann_milk','wb'))\n",
    "\n",
    "# Read pickle file into variable to use model\n",
    "model_pkl_ann = pickle.load(open('./../artifacts/pkl_ann_milk','rb'))\n",
    "\n",
    "\n",
    "## Example using pickle file with saved ANN model\n",
    "\n",
    "# take input from source as array\n",
    "data_input_from_webapp = np.array([ 357.3,  362.5,  172. , 1440.2, 2136.5])\n",
    "\n",
    "# scale input with same scaler as used in model\n",
    "scale_data_from_webapp = scaler_x.transform(data_input_from_webapp.reshape(1, -1))\n",
    "\n",
    "# predict scaled value\n",
    "scaled_prediction = bestANNModel.predict(scale_data_from_webapp)\n",
    "\n",
    "# descale prediction back to normal value\n",
    "prediction = scaler_y.inverse_transform(scaled_prediction)\n",
    "print('\\n Expected Milk Production is ',prediction[0][0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7dbd8c",
   "metadata": {},
   "source": [
    "# Next step Model Deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
